{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source:\n",
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "\n",
    "# Initial Data Prep\n",
    "\n",
    "**Read in data, create new \"first_genre\" column, and split into train / test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movie_df.csv', encoding='utf8', converters={'genre_ids':literal_eval})\n",
    "df = df[df['genre_ids'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>first_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>278</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>28.527767</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9773</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>238</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>36.965452</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7394</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[18, 36, 10752]</td>\n",
       "      <td>424</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>19.945455</td>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5518</td>\n",
       "      <td>tt0108052</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>240</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>30.191804</td>\n",
       "      <td>1974-12-20</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4249</td>\n",
       "      <td>tt0071562</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18, 9648]</td>\n",
       "      <td>452522</td>\n",
       "      <td>Standalone version of the series pilot with an...</td>\n",
       "      <td>5.969249</td>\n",
       "      <td>1989-12-31</td>\n",
       "      <td>Twin Peaks</td>\n",
       "      <td>8.4</td>\n",
       "      <td>123</td>\n",
       "      <td>tt0278784</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre_ids      id                                           overview  \\\n",
       "0         [18, 80]     278  Framed in the 1940s for the double murder of h...   \n",
       "1         [18, 80]     238  Spanning the years 1945 to 1955, a chronicle o...   \n",
       "2  [18, 36, 10752]     424  The true story of how businessman Oskar Schind...   \n",
       "3         [18, 80]     240  In the continuing saga of the Corleone crime f...   \n",
       "4       [18, 9648]  452522  Standalone version of the series pilot with an...   \n",
       "\n",
       "   popularity release_date                     title  vote_average  \\\n",
       "0   28.527767   1994-09-23  The Shawshank Redemption           8.5   \n",
       "1   36.965452   1972-03-14             The Godfather           8.5   \n",
       "2   19.945455   1993-11-29          Schindler's List           8.4   \n",
       "3   30.191804   1974-12-20    The Godfather: Part II           8.4   \n",
       "4    5.969249   1989-12-31                Twin Peaks           8.4   \n",
       "\n",
       "   vote_count    imdb_id  first_genre  \n",
       "0        9773  tt0111161           18  \n",
       "1        7394  tt0068646           18  \n",
       "2        5518  tt0108052           18  \n",
       "3        4249  tt0071562           18  \n",
       "4         123  tt0278784           18  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_genre'] = df['genre_ids'].apply(lambda x: x[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=9001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "We will be using a few sklearn functions to assist in this portion\n",
    "\n",
    "**CountVectorizer**\n",
    "\n",
    "This creates a Document-Term matrix with the dimensions [n_samples, n_features]\n",
    "\n",
    "**TfidfTransformer**\n",
    "\n",
    "TF stands for *Term Frequency*. It is the count of each word divided by the toal words in the document. TFIDF stands for *Term Frequency Times Inverse Document Frequency*. This function reduces the weights of common words, such as (this, is, an, etc.)\n",
    "\n",
    "**Pipeline**\n",
    "This allows us to make multiple manipulations to our data in a single line of code. It makes our code more concise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.334 \n",
      "Test Accuracy: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf = text_clf.fit(train['overview'], train['first_genre'])\n",
    "nb_train_predict = text_clf.predict(train['overview'])\n",
    "nb_test_predict = text_clf.predict(test['overview'])\n",
    "\n",
    "nb_train_accuracy = np.mean(nb_train_predict == train['first_genre'])\n",
    "nb_test_accuracy = np.mean(nb_test_predict == test['first_genre'])\n",
    "\n",
    "print(\"Train Accuracy: {0} \\nTest Accuracy: {1}\".format(nb_train_accuracy,nb_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0 \n",
      "Test Accuracy: 0.364\n"
     ]
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "_ = text_clf_svm.fit(train['overview'], train['first_genre'])\n",
    "\n",
    "svm_train_predict = text_clf_svm.predict(train['overview'])\n",
    "svm_test_predict = text_clf_svm.predict(test['overview'])\n",
    "\n",
    "svm_train_accuracy = np.mean(svm_train_predict == train['first_genre'])\n",
    "svm_test_accuracy = np.mean(svm_test_predict == test['first_genre'])\n",
    "\n",
    "print(\"Train Accuracy: {0} \\nTest Accuracy: {1}\".format(svm_train_accuracy,svm_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like extreme over-fitting is occuring                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train['overview'], train['first_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.338"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Stop Words - Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.376 \n",
      "Test Accuracy: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf = text_clf.fit(train['overview'], train['first_genre'])\n",
    "nb_train_predict = text_clf.predict(train['overview'])\n",
    "nb_test_predict = text_clf.predict(test['overview'])\n",
    "\n",
    "nb_train_accuracy = np.mean(nb_train_predict == train['first_genre'])\n",
    "nb_test_accuracy = np.mean(nb_test_predict == test['first_genre'])\n",
    "\n",
    "print(\"Train Accuracy: {0} \\nTest Accuracy: {1}\".format(nb_train_accuracy,nb_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Stop Words - Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0 \n",
      "Test Accuracy: 0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "_ = text_clf_svm.fit(train['overview'], train['first_genre'])\n",
    "\n",
    "svm_train_predict = text_clf_svm.predict(train['overview'])\n",
    "svm_test_predict = text_clf_svm.predict(test['overview'])\n",
    "\n",
    "svm_train_accuracy = np.mean(svm_train_predict == train['first_genre'])\n",
    "svm_test_accuracy = np.mean(svm_test_predict == test['first_genre'])\n",
    "\n",
    "print(\"Train Accuracy: {0} \\nTest Accuracy: {1}\".format(svm_train_accuracy,svm_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(train['overview'], train['first_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
